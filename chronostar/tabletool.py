"""
A bunch of functions that help handle stellar data stored as
astropy table.
"""

import numpy as np
from astropy.table import Table
from astropy.units.core import UnitConversionError

from . import coordinate
from . import transform

def load(filename, **kwargs):
    """Cause I'm too lazy to import Astropy.table.Table in terminal"""
    return Table.read(filename, **kwargs)

def read(filename, **kwargs):
    """Cause I'm too lazy to import Astropy.table.Table in terminal"""
    return load(filename, **kwargs)


def get_historical_cart_colnames():
    """
    Colnames look like X, Y, Z...
    dX, dY, dZ
    c_XY, c_CU

    (as opposed to modern colnames:
    X, Y, Z...
    X_error, Y_error ...
    X_Y_corr,
    """
    main_colnames = 'XYZUVW'
    error_colnames = ['d'+el for el in main_colnames]
    corr_colnames = []
    for i, colname1 in enumerate(main_colnames):
        for colname2 in main_colnames[i+1:]:
            corr_colnames.append('c_{}{}'.format(colname1, colname2))
    return main_colnames, error_colnames, corr_colnames


def get_colnames(main_colnames=None, error_colnames=None, corr_colnames=None,
                 cartesian=True):
    """
    Utility function for generating standard column names

    Parameters
    ----------
    main_colnames: [6] str array_like {None}
        The column names of the measurements. If left as None then
        if `cartesian` is true:
            ['X', 'Y', 'Z', 'U', 'V', 'W']
        if `cartesian` is false:
            ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'radial_velocity']
    error_colnames: [6] str array_like {None}
        The column names of the measurements. If left as None then
        we try to infer the names by appending '_error' to the main
        column names.
    corr_colnames: [15] str array_like {None}
        The column names of the correlations between the errors of
        each measurement pair. If left as None we try to infer the
        names by pairing each measurmenet and appending '_corr', e.g.:
        'X_Y_corr'.

    Notes
    -----
    If all column names are provided as argument, this function does
    nothing.

    The default format for column names for errors and correlations is,
    e.g.:
        X_error, Y_error, ...
        X_Y_corr, X_Z_corr, X_U_corr, X_V_corr, X_W_corr, Y_Z_corr, ...
    The correlations are listed in the same way one would read the upper
    triangle of the correlation matrix, where the rows (and columns) of
    the matrix are in the same order as `main_colnames`.
    """
    if main_colnames is None:
        if cartesian:
            # main_colnames = [el for el in 'XYZUVW']
            main_colnames = ['X', 'Y', 'Z', 'U', 'V', 'W']
        else:       # provide astrometric column names
            main_colnames = [
                'ra', 'dec', 'parallax', 'pmra', 'pmdec', 'radial_velocity',
            ]
    if error_colnames is None:
        error_colnames = [el+'_error' for el in main_colnames]
    if corr_colnames is None:
        corr_colnames = []
        for i, colname1 in enumerate(main_colnames):
            for colname2 in main_colnames[i + 1:]:
                corr_colnames.append('{}_{}_corr'.format(
                        colname1, colname2
                ))
    return main_colnames, error_colnames, corr_colnames


def build_data_dict_from_table(table, main_colnames=None, error_colnames=None,
                               corr_colnames=None, cartesian=True,
                               historical=False, only_means=False,
                               get_background_overlaps=True,
                               background_colname=None, ):
    """
    Use data in tale columns to construct arrays of means and covariance
    matrices.

    Parameters
    ----------
    table : astropy table -or- string
        The table (or path to table) which holds the required data
    main_colnames : [6] string array_like
        Set of column names of the main measurements
        e.g. ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'radial_velocity']
        would be the input for the default format of Gaia data
    error_colnames : [6] string array_like {None}
        Set of column names for the errors. If left as None will be
        generated by appending '_error' to each of the main_colnames
    corr_colnames : [15] string array_like {None}
        Set of column names for the pairwise correlations between each
        of the six main measurements. If left as None will be generated
        by joining each pair of main_colnames with an underscore then
        appending '_corr'.
        It is assumed that the correlation column names are given in
        a certain order based on input order of main_colnames.
        e.g. ['ra_dec_corr', 'ra_parallax_corr', ... 'ra_radial_velocity_corr',
              'dec_parallax_corr', ... 'dec_radial_velocity_corr',
              'parallax_pmra_corr' ... etc]

    Returns
    -------
    means : [n,6] float array_like
        Array of the mean measurements
    covs : [n,6,6] float array_like
        Array of the covariance matrix for each of the `n` measured objects

    """
    # Tidy up input
    if isinstance(table, str):
        table = Table.read(table)
    if historical:
        main_colnames, error_colnames, corr_colnames =\
            get_historical_cart_colnames()
    else:
        main_colnames, error_colnames, corr_colnames = get_colnames(
                main_colnames=main_colnames, error_colnames=error_colnames,
                corr_colnames=corr_colnames, cartesian=cartesian
        )

    # Generate means
    means = np.vstack([table[col] for col in main_colnames]).T
    if only_means:
        return means
    results_dict = {}
    results_dict['means'] = means

    # Insert background overlaps
    if get_background_overlaps:
        if background_colname is None:
            background_colname = 'background_log_overlap'
    if background_colname in table.colnames:
        results_dict['bg_lnols'] = np.array(table[background_colname])

    # Generate covariance matrices
    nstars = len(table)
    standard_devs = np.vstack([table[col] for col in error_colnames]).T

    # Detect mismatch in units and scale standard_devs appropriately
    # If units can't be converted
    for ix, (main_colname, error_colname) in\
            enumerate(zip(main_colnames, error_colnames)):
        if table[main_colname].unit != table[error_colname].unit:
            try:
                scale_factor =\
                    table[error_colname].unit.to(table[main_colname].unit)
                standard_devs[:,ix] *= scale_factor
            except UnitConversionError:
                print(main_colname, error_colname)
                raise UserWarning('Units are not convertible between '
                                  'measurments and errors. Are you sure '
                                  'you provided column names in a consistent '
                                  'ordering?')
            except AttributeError:
                # Units haven't been provided. Which is allowed but discouraged
                pass

    # Initialise an array of 6x6 identity matrices
    covs = np.array(nstars * [np.eye(6)])

    # Then turn into correlation matrices by incorporating correlation columns
    indices = np.triu_indices(6,1)      # the indices of the upper right
                                        # triangle, excluding main diagonal
    for ix in range(len(corr_colnames)):
        try:
            fst_ix = indices[0][ix]
            snd_ix = indices[1][ix]
            covs[:, fst_ix, snd_ix] = table[corr_colnames[ix]]
            covs[:, snd_ix, fst_ix] = table[corr_colnames[ix]]
        except KeyError:        # Correlations are allowed to be missing
            pass

    # Now multiply through the standard deviations along both axes
    # First along each column
    # We use einstein notation here such that 'ijk,ij->ijk' means
    # multiply the 'ijk'th element from covs by the 'ij'th element from
    # standard_devs. More thoroughly: for the i'th covariance matrix,
    # and the i'th 6D standard deviation vector, multiply the j'th row
    # by the j'th std
    covs = np.einsum('ijk,ij->ijk', covs, standard_devs)    # the rows
    covs = np.einsum('ijk,ik->ijk', covs, standard_devs)    # the columsn
    results_dict['covs'] = covs
    return results_dict


def append_cart_cols_to_table(table, main_colnames=None, error_colnames=None,
                              corr_colnames=None):
    """
    Insert empty place holder columns for cartesian values

    Parameters
    ----------
    table : astropy.table.Table object
        Modifies table in place by appending empty columns for cartesian
        values. Default values in column are `np.nan`.

    Returns
    -------
    None
    """
    # Tidy input
    if isinstance(table, str):
        table = Table.read(table)
    main_colnames, error_colnames, corr_colnames =\
        get_colnames(main_colnames, error_colnames, corr_colnames,
                     cartesian=True)

    # Set up order of column names in table
    cart_colnames = []
    for measure, error in zip(main_colnames, error_colnames):
        cart_colnames.append(measure)
        cart_colnames.append(error)
    for corr in corr_colnames:
        cart_colnames.append(corr)

    # Insert blank rows (default value 'np.nan') with appropriate units
    nrows = len(table)
    empty_col = np.array(nrows * [np.nan])
    units = 6*['pc'] + 6*['km/s'] + 15*[None]
    for col_name, unit in zip(cart_colnames, units):
        table[col_name] = empty_col
        table[col_name].unit = unit


def convert_astro2cart(astr_mean, astr_cov):
    """
    Convert astrometry data (mean and covariance) into cartesian
    coordinates, centred on the local standard of rest (Schoenrich 2010).

    Parameters
    ----------
    astr_mean: [6] float array_like
        The central estimate of a star's astrometry values. Provided in
        the order:
            ra [deg]
            dec [deg]
            parallax [mas]
            pmra*cos(dec) [mas/yr]
            pmdec [mas/yr]
            radial velocity [km/s]
    astr_cov: [6,6] float array_like
        The covariance matrix of the measurments with columns (and rows)
        in same order as `astr_mean`.

    Returns
    -------
    xyzuvw_mean: [6] float array_like
        The cartesian mean (XYZUVW)
    xyzuvw_cov: [6,6] float array_like
        The carteisan covariance matrix
    """
    xyzuvw_mean = coordinate.convert_astrometry2lsrxyzuvw(astr_mean)

    xyzuvw_cov = transform.transform_covmatrix(
            cov=astr_cov, trans_func=coordinate.convert_astrometry2lsrxyzuvw,
            loc=astr_mean
    )

    return xyzuvw_mean, xyzuvw_cov


def insert_data_into_row(row, mean, cov, main_colnames=None, error_colnames=None,
                         corr_colnames=None, cartesian=True):
    """
    Insert data, error and correlations into a single row

    Given the mean and covariance matrix, we derive the standard
    deviations in each dimension as well as each pair-wise correlation,
    which are then inserted into the row (as per the provided column names).

    The columns must already exist!

    Parameters
    row: astropy table row
        The row in which the data will be inserted, with required columns
        already existing
    mean: [6] float array
        The mean of data
    cov: [6,6] float array
        The covariance matrix of data
    """

    main_colnames, error_colnames, corr_colnames = get_colnames(
            main_colnames, error_colnames, corr_colnames, cartesian=cartesian
    )
    # Insert mean data
    for ix, main_colname in enumerate(main_colnames):
        row[main_colname] = mean[ix]

    # Insert errors
    standard_devs = np.sqrt(np.diagonal(cov))
    for ix, error_colname in enumerate(error_colnames):
        row[error_colname] = standard_devs[ix]

    # Build correlation matrix by dividing through by stdevs in both axes
    corr_matrix = cov / standard_devs / standard_devs.reshape(6, 1)

    # Insert correlations
    indices = np.triu_indices(6,1)      # the indices of the upper right
                                        # triangle, excluding main diagonal
    for ix in range(len(corr_colnames)):
        try:
            fst_ix = indices[0][ix]
            snd_ix = indices[1][ix]
            row[corr_colnames[ix]] = corr_matrix[fst_ix, snd_ix]
        except KeyError:
            # It's fine if some correlation columns are missing
            pass


def insert_column(table, col_data, col_name, filename=''):
    """
    Little helper to insert column data

    Parameters
    ----------
    table: astropy table
        the table in which the new column will be inserted
    col_data: array_like
        An array of the column data. Must be same length as table
        (we don't check this)
    col_name: str
        The name of the new column
    filename: str {''}
        If not empty, save the new table to file

    Returns
    -------
    table: astropy table
        The same table, with the modification.
    """
    table[col_name] = col_data
    if filename != '':
        table.write(filename, overwrite=True)
    return table


def convert_table_astro2cart(table, return_table=False, write_table=False,
                             main_colnames=None, error_colnames=None,
                             corr_colnames=None, filename=''):
    """
    Use this function to convert astrometry data to cartesian data.

    Parameters
    ----------
    table: astropy table (or string)
        The table with astrometry data (and radial velocities), either
        with column names consistent with defaults, or provided as input.
        If column names aren't specified we assume the measurements
        have column names:
            ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'radial_velocity']
        With the error column names:
            ['ra_error', 'dec_error', ... ]
        And correlation column names:
            ['ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr' ... ,
             'dec_parallax_corr', 'dec_pmra_corr' ... ,
             'parallax_pmra_corr', ... ,
             ... ]
    return_table: bool {False}
        Whether to return the converted table
    write_table: bool {False}
        Whether to write the converted table to filename. It is not
        sufficient to simply supply a filename to write as we do not
        want to risk overwriting someone's table (even though we simply
        extend with new columns).
    main_colnames: [6] string array_like
        Set of column names of the main measurements
        e.g. ['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'radial_velocity']
        would be the input for the default format of Gaia data
    error_colnames: [6] string array_like {None}
        Set of column names for the errors. If left as None will be
        generated by appending '_error' to each of the main_colnames
    corr_colnames: [15] string array_like {None}
        Set of column names for the pairwise correlations between each
        of the six main measurements. If left as None will be generated
        by joining each pair of main_colnames with an underscore then
        appending '_corr'.
        It is assumed that the correlation column names are given in
        a certain order based on input order of main_colnames.
        e.g. ['ra_dec_corr', 'ra_parallax_corr', ... 'ra_radial_velocity_corr',
              'dec_parallax_corr', ... 'dec_radial_velocity_corr',
              'parallax_pmra_corr' ... etc]
    filename: str {''}
        Save filename for storing the resulting table

    Returns
    -------
    res: astropy table
        If `return_table` flag is set, will return the resulting
        astropy table
    """
    if isinstance(table, str):
        if filename and not write_table:
            raise UserWarning('Specify how to handle result, I won\'t'
                              'overwrite without explicit permission.')
        filename = table
        table = Table.read(table)

    astr_main_colnames, astr_error_colnames, astr_corr_colnames =\
        get_colnames(main_colnames=main_colnames, error_colnames=error_colnames,
                     corr_colnames=corr_colnames, cartesian=False)

    data = build_data_dict_from_table(table,
                                      astr_main_colnames,
                                      astr_error_colnames,
                                      astr_corr_colnames)

    # if cartesian columns don't exist, then insert them
    if 'X_V_corr' not in table.keys() and 'c_XV' not in table.keys():
        append_cart_cols_to_table(table)
    cart_main_colnames, cart_error_colnames, cart_corr_colnames = \
        get_colnames(cartesian=True)

    # Iteratively transform data to cartesian coordinates, storing as we go
#     cart_means = np.zeros(astr_means.shape)
#     cart_covs = np.zeros(astr_covs.shape)
#     for ix, (astr_mean, astr_cov) in enumerate(zip(astr_means, astr_covs)):
#         cart_means[ix], cart_covs[ix] = convertAstroToCart(astr_mean, astr_cov)


    for row, astr_mean, astr_cov in zip(table, data['means'], data['covs']):
        cart_mean, cart_cov = convert_astro2cart(astr_mean, astr_cov)
        insert_data_into_row(row, cart_mean, cart_cov,
                             main_colnames=cart_main_colnames,
                             error_colnames=cart_error_colnames,
                             corr_colnames=cart_corr_colnames
                             )

    if filename and write_table:
        table.write(filename, overwrite=True)

    if return_table:
        return table

